{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocess the TJH Dataset"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from datasets.preprocess.tools import forward_fill_pipeline, normalize_dataframe\n",
    "\n",
    "data_dir = \"./datasets/tjh/\"\n",
    "Path(os.path.join(data_dir, 'processed')).mkdir(parents=True, exist_ok=True)\n",
    "Path(os.path.join(data_dir, 'statistics')).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "SEED = 42"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read data from files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel(os.path.join(data_dir, 'raw', 'time_series_375_prerpocess_en.xlsx'))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess Data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rename columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.rename(columns={\"PATIENT_ID\": \"PatientID\", \"outcome\": \"Outcome\", \"gender\": \"Sex\", \"age\": \"Age\", \"RE_DATE\": \"RecordTime\", \"Admission time\": \"AdmissionTime\", \"Discharge time\": \"DischargeTime\"})"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fill PatientID column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['PatientID'].fillna(method='ffill', inplace=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Format data values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gender transformation: 1--male, 0--female\n",
    "df['Sex'].replace(2, 0, inplace=True)\n",
    "\n",
    "# only reserve y-m-d precision for `RE_DATE` and `Discharge time` columns\n",
    "df['RecordTime'] = df['RecordTime'].dt.strftime('%Y-%m-%d')\n",
    "df['DischargeTime'] = df['DischargeTime'].dt.strftime('%Y-%m-%d')\n",
    "df['AdmissionTime'] = df['AdmissionTime'].dt.strftime('%Y-%m-%d')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exclude patients with missing labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna(subset = ['PatientID', 'RecordTime', 'DischargeTime'], how='any')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate the Length-of-Stay (LOS) label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['LOS'] = (pd.to_datetime(df['DischargeTime']) - pd.to_datetime(df['RecordTime'])).dt.days\n",
    "\n",
    "# Notice: Set negative LOS values to 0\n",
    "df['LOS'] = df['LOS'].apply(lambda x: 0 if x < 0 else x)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Drop columns whose values are all the same or all NaN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop '2019-nCoV nucleic acid detection' column \n",
    "df = df.drop(columns=['2019-nCoV nucleic acid detection'])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Record feature names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "basic_records = ['PatientID', 'RecordTime', 'AdmissionTime', 'DischargeTime']\n",
    "target_features = ['Outcome', 'LOS']\n",
    "demographic_features = ['Sex', 'Age']\n",
    "labtest_features = ['Hypersensitive cardiac troponinI', 'hemoglobin', 'Serum chloride', 'Prothrombin time', 'procalcitonin', 'eosinophils(%)', 'Interleukin 2 receptor', 'Alkaline phosphatase', 'albumin', 'basophil(%)', 'Interleukin 10', 'Total bilirubin', 'Platelet count', 'monocytes(%)', 'antithrombin', 'Interleukin 8', 'indirect bilirubin', 'Red blood cell distribution width ', 'neutrophils(%)', 'total protein', 'Quantification of Treponema pallidum antibodies', 'Prothrombin activity', 'HBsAg', 'mean corpuscular volume', 'hematocrit', 'White blood cell count', 'Tumor necrosis factorα', 'mean corpuscular hemoglobin concentration', 'fibrinogen', 'Interleukin 1β', 'Urea', 'lymphocyte count', 'PH value', 'Red blood cell count', 'Eosinophil count', 'Corrected calcium', 'Serum potassium', 'glucose', 'neutrophils count', 'Direct bilirubin', 'Mean platelet volume', 'ferritin', 'RBC distribution width SD', 'Thrombin time', '(%)lymphocyte', 'HCV antibody quantification', 'D-D dimer', 'Total cholesterol', 'aspartate aminotransferase', 'Uric acid', 'HCO3-', 'calcium', 'Amino-terminal brain natriuretic peptide precursor(NT-proBNP)', 'Lactate dehydrogenase', 'platelet large cell ratio ', 'Interleukin 6', 'Fibrin degradation products', 'monocytes count', 'PLT distribution width', 'globulin', 'γ-glutamyl transpeptidase', 'International standard ratio', 'basophil count(#)', 'mean corpuscular hemoglobin ', 'Activation of partial thromboplastin time', 'Hypersensitive c-reactive protein', 'HIV antibody quantification', 'serum sodium', 'thrombocytocrit', 'ESR', 'glutamic-pyruvic transaminase', 'eGFR', 'creatinine']\n",
    "\n",
    "require_impute_features = labtest_features\n",
    "normalize_features = ['Age'] + labtest_features + ['LOS']"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set negative values to NaN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set negative values to NaN\n",
    "df[df[demographic_features + labtest_features] < 0] = np.nan"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merge by date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge by PatientID and RecordTime\n",
    "df = df.groupby(['PatientID', 'RecordTime', 'AdmissionTime', 'DischargeTime'], dropna=True, as_index = False).mean()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Change the order of columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[ basic_records + target_features + demographic_features + labtest_features ]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Export data to files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(os.path.join(data_dir, 'processed', 'tjh_dataset_formatted.csv'), index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stratified split dataset into train, validation and test sets\n",
    "\n",
    "- Also include (Imputation & Normalization & Outlier Filtering) steps\n",
    "- The train, validation and test sets are saved in the `./processed` folder\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10-fold dataset setting\n",
    "\n",
    "- use 8:1:1 10-fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_folds = 10\n",
    "\n",
    "# Group the dataframe by patient ID\n",
    "grouped = df.groupby('PatientID')\n",
    "\n",
    "# Split the patient IDs into train/val/test sets\n",
    "patients = np.array(list(grouped.groups.keys()))\n",
    "kf = StratifiedKFold(n_splits=num_folds, shuffle=True, random_state=SEED)\n",
    "\n",
    "for fold, (train_val_index, test_index) in enumerate(kf.split(patients, df.groupby('PatientID')['Outcome'].first())):\n",
    "    # Get the train/val/test patient IDs for the current fold\n",
    "    train_val_patients, test_patients = patients[train_val_index], patients[test_index]\n",
    "\n",
    "    # Split the train_val_patients into train/val sets\n",
    "    train_patients, val_patients = train_test_split(train_val_patients, test_size=1/(num_folds-1), random_state=SEED, stratify=df[df['PatientID'].isin(train_val_patients)].groupby('PatientID')['Outcome'].first())\n",
    "\n",
    "    # Create train, val, and test dataframes for the current fold\n",
    "    train_df = df[df['PatientID'].isin(train_patients)]\n",
    "    val_df = df[df['PatientID'].isin(val_patients)]\n",
    "    test_df = df[df['PatientID'].isin(test_patients)]\n",
    "    \n",
    "    assert len(train_df) + len(val_df) + len(test_df) == len(df)\n",
    "\n",
    "    # Save the train, val, and test dataframes for the current fold to csv files\n",
    "    \n",
    "    fold_dir = os.path.join(data_dir, 'processed', f'fold_{fold}')\n",
    "    Path(fold_dir).mkdir(parents=True, exist_ok=True)\n",
    "    # train_df.to_csv(os.path.join(fold_dir, \"train_raw.csv\"), index=False)\n",
    "    # val_df.to_csv(os.path.join(fold_dir, \"val_raw.csv\"), index=False)\n",
    "    # test_df.to_csv(os.path.join(fold_dir, \"test_raw.csv\"), index=False)\n",
    "\n",
    "    # Calculate the mean and std of the train set (include age, lab test features, and LOS) on the data in 5% to 95% quantile range\n",
    "\n",
    "    # Normalize data\n",
    "    train_df, val_df, test_df, default_fill, los_info, train_mean, train_std = normalize_dataframe(train_df, val_df, test_df, normalize_features)\n",
    "    \n",
    "    # Drop rows if all features are recorded NaN\n",
    "    train_df = train_df.dropna(axis=0, how='all', subset=normalize_features)\n",
    "    val_df = val_df.dropna(axis=0, how='all', subset=normalize_features)\n",
    "    test_df = test_df.dropna(axis=0, how='all', subset=normalize_features)\n",
    "\n",
    "    # # Save the train, val, and test dataframes for the current fold to csv files\n",
    "    # train_df.to_csv(os.path.join(fold_dir, \"train_after_zscore.csv\"), index=False)\n",
    "    # val_df.to_csv(os.path.join(fold_dir, \"val_after_zscore.csv\"), index=False)\n",
    "    # test_df.to_csv(os.path.join(fold_dir, \"test_after_zscore.csv\"), index=False)\n",
    "\n",
    "    # Forward Imputation after grouped by PatientID\n",
    "    # Notice: if a patient has never done certain lab test, the imputed value will be the median value calculated from train set\n",
    "    train_x, train_y, train_pid = forward_fill_pipeline(train_df, default_fill, demographic_features, labtest_features, target_features, require_impute_features)\n",
    "    val_x, val_y, val_pid = forward_fill_pipeline(val_df, default_fill, demographic_features, labtest_features, target_features, require_impute_features)\n",
    "    test_x, test_y, test_pid = forward_fill_pipeline(test_df, default_fill, demographic_features, labtest_features, target_features, require_impute_features)\n",
    "\n",
    "    # Save the imputed dataset to pickle file\n",
    "    pd.to_pickle(train_x, os.path.join(fold_dir, \"train_x.pkl\"))\n",
    "    pd.to_pickle(train_y, os.path.join(fold_dir, \"train_y.pkl\"))\n",
    "    pd.to_pickle(train_pid, os.path.join(fold_dir, \"train_pid.pkl\"))\n",
    "    pd.to_pickle(val_x, os.path.join(fold_dir, \"val_x.pkl\"))\n",
    "    pd.to_pickle(val_y, os.path.join(fold_dir, \"val_y.pkl\"))\n",
    "    pd.to_pickle(val_pid, os.path.join(fold_dir, \"val_pid.pkl\"))\n",
    "    pd.to_pickle(test_x, os.path.join(fold_dir, \"test_x.pkl\"))\n",
    "    pd.to_pickle(test_y, os.path.join(fold_dir, \"test_y.pkl\"))\n",
    "    pd.to_pickle(test_pid, os.path.join(fold_dir, \"test_pid.pkl\"))\n",
    "    pd.to_pickle(los_info, os.path.join(fold_dir, \"los_info.pkl\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hold-out dataset setting (Stratified)\n",
    "\n",
    "- For TJH dataset, use 7:1:2 splitting strategy, 70% training, 10% validation, 20% testing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group the dataframe by patient ID\n",
    "grouped = df.groupby('PatientID')\n",
    "\n",
    "# Get the patient IDs and outcomes\n",
    "patients = np.array(list(grouped.groups.keys()))\n",
    "patients_outcome = np.array([grouped.get_group(patient_id)['Outcome'].iloc[0] for patient_id in patients])\n",
    "\n",
    "# Get the train_val/test patient IDs\n",
    "train_val_patients, test_patients = train_test_split(patients, test_size=20/100, random_state=SEED, stratify=patients_outcome)\n",
    "\n",
    "# Get the train/val patient IDs\n",
    "train_val_patients_outcome = np.array([grouped.get_group(patient_id)['Outcome'].iloc[0] for patient_id in train_val_patients])\n",
    "train_patients, val_patients = train_test_split(train_val_patients, test_size=10/80, random_state=SEED, stratify=train_val_patients_outcome)\n",
    "# Create train, val, test dataframes for the current fold\n",
    "train_df = df[df['PatientID'].isin(train_patients)]\n",
    "val_df = df[df['PatientID'].isin(val_patients)]\n",
    "test_df = df[df['PatientID'].isin(test_patients)]\n",
    "save_dir = os.path.join(data_dir, 'processed', 'fold_10') # forward fill\n",
    "Path(save_dir).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# # Save the train, val, and test dataframes for the current fold to csv files\n",
    "# train_df.to_csv(os.path.join(save_dir, \"train_raw.csv\"), index=False)\n",
    "# val_df.to_csv(os.path.join(save_dir, \"val_raw.csv\"), index=False)\n",
    "# test_df.to_csv(os.path.join(save_dir, \"test_raw.csv\"), index=False)\n",
    "# Calculate the mean and std of the train set (include age, lab test features, and LOS) on the data in 5% to 95% quantile range\n",
    "train_df, val_df, test_df, default_fill, los_info, train_mean, train_std = normalize_dataframe(train_df, val_df, test_df, normalize_features)\n",
    "\n",
    "# # Save the zscored dataframes to csv files\n",
    "# train_df.to_csv(os.path.join(save_dir, \"train_after_zscore.csv\"), index=False)\n",
    "# val_df.to_csv(os.path.join(save_dir, \"val_after_zscore.csv\"), index=False)\n",
    "# test_df.to_csv(os.path.join(save_dir, \"test_after_zscore.csv\"), index=False)\n",
    "\n",
    "# Forward Imputation after grouped by PatientID\n",
    "# Notice: if a patient has never done certain lab test, the imputed value will be the median value calculated from train set\n",
    "train_x, train_y, train_pid = forward_fill_pipeline(train_df, default_fill, demographic_features, labtest_features, target_features, require_impute_features)\n",
    "val_x, val_y, val_pid = forward_fill_pipeline(val_df, default_fill, demographic_features, labtest_features, target_features, require_impute_features)\n",
    "test_x, test_y, test_pid = forward_fill_pipeline(test_df, default_fill, demographic_features, labtest_features, target_features, require_impute_features)\n",
    "\n",
    "# Save the imputed dataset to pickle file\n",
    "pd.to_pickle(train_x, os.path.join(save_dir, \"train_x.pkl\"))\n",
    "pd.to_pickle(train_y, os.path.join(save_dir, \"train_y.pkl\"))\n",
    "pd.to_pickle(train_pid, os.path.join(save_dir, \"train_pid.pkl\"))\n",
    "pd.to_pickle(val_x, os.path.join(save_dir, \"val_x.pkl\"))\n",
    "pd.to_pickle(val_y, os.path.join(save_dir, \"val_y.pkl\"))\n",
    "pd.to_pickle(val_pid, os.path.join(save_dir, \"val_pid.pkl\"))\n",
    "pd.to_pickle(test_x, os.path.join(save_dir, \"test_x.pkl\"))\n",
    "pd.to_pickle(test_y, os.path.join(save_dir, \"test_y.pkl\"))\n",
    "pd.to_pickle(test_pid, os.path.join(save_dir, \"test_pid.pkl\"))\n",
    "pd.to_pickle(los_info, os.path.join(save_dir, \"los_info.pkl\")) # LOS statistics (calculated from the train set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hold-out dataset setting (According to admission time)\n",
    "\n",
    "- For TJH dataset, use 7:1:2 splitting strategy, 70% training, 10% validation, 20% testing\n",
    "\n",
    "**time order**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group the dataframe by PatientID\n",
    "grouped = df.groupby('PatientID')\n",
    "\n",
    "# Get the first AdmissionTime for each patient\n",
    "patients_admission_time = {patient_id: grouped.get_group(patient_id)['AdmissionTime'].iloc[0] for patient_id in grouped.groups.keys()}\n",
    "\n",
    "# Sort patient IDs by first AdmissionTime\n",
    "sorted_patients = sorted(patients_admission_time, key=patients_admission_time.get)\n",
    "\n",
    "# Calculate the indices for splitting\n",
    "train_idx = int(len(sorted_patients) * 0.6)\n",
    "val_idx = int(len(sorted_patients) * 0.8)\n",
    "\n",
    "# Split the patient IDs into train, validation, and test sets\n",
    "train_patients = sorted_patients[:train_idx]\n",
    "val_patients = sorted_patients[train_idx:val_idx]\n",
    "test_patients = sorted_patients[val_idx:]\n",
    "\n",
    "# Create train, val, test, dataframes for the current fold\n",
    "train_df = df[df['PatientID'].isin(train_patients)]\n",
    "val_df = df[df['PatientID'].isin(val_patients)]\n",
    "test_df = df[df['PatientID'].isin(test_patients)]\n",
    "save_dir = os.path.join(data_dir, 'processed', 'fold_11') # forward fill\n",
    "Path(save_dir).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "train_df, val_df, test_df, default_fill, los_info, train_mean, train_std = normalize_dataframe(train_df, val_df, test_df, normalize_features)\n",
    "\n",
    "# Forward Imputation after grouped by PatientID\n",
    "# Notice: if a patient has never done certain lab test, the imputed value will be the median value calculated from train set\n",
    "train_x, train_y, train_pid = forward_fill_pipeline(train_df, default_fill, demographic_features, labtest_features, target_features, require_impute_features)\n",
    "val_x, val_y, val_pid = forward_fill_pipeline(val_df, default_fill, demographic_features, labtest_features, target_features, require_impute_features)\n",
    "test_x, test_y, test_pid = forward_fill_pipeline(test_df, default_fill, demographic_features, labtest_features, target_features, require_impute_features)\n",
    "\n",
    "# Save the imputed dataset to pickle file\n",
    "pd.to_pickle(train_x, os.path.join(save_dir, \"train_x.pkl\"))\n",
    "pd.to_pickle(train_y, os.path.join(save_dir, \"train_y.pkl\"))\n",
    "pd.to_pickle(train_pid, os.path.join(save_dir, \"train_pid.pkl\"))\n",
    "pd.to_pickle(val_x, os.path.join(save_dir, \"val_x.pkl\"))\n",
    "pd.to_pickle(val_y, os.path.join(save_dir, \"val_y.pkl\"))\n",
    "pd.to_pickle(val_pid, os.path.join(save_dir, \"val_pid.pkl\"))\n",
    "pd.to_pickle(test_x, os.path.join(save_dir, \"test_x.pkl\"))\n",
    "pd.to_pickle(test_y, os.path.join(save_dir, \"test_y.pkl\"))\n",
    "pd.to_pickle(test_pid, os.path.join(save_dir, \"test_pid.pkl\"))\n",
    "pd.to_pickle(los_info, os.path.join(save_dir, \"los_info.pkl\")) # LOS statistics (calculated from the train set)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
